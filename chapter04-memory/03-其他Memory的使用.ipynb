{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1ã€ConversationTokenMemoryç®€ä»‹\n",
    "\n",
    "ä¸¾ä¾‹1ï¼š"
   ],
   "id": "c66baef6ba0a8e1e"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T06:29:41.374892800Z",
     "start_time": "2025-12-10T06:29:41.327682100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory, ConversationSummaryBufferMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=chat_model,\n",
    "    max_token_limit=20\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\":\"ä½ å¥½å—ï¼Ÿ\"},{\"output\":\"æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢ï¼\"})\n",
    "memory.save_context({\"input\":\"ä½ æ˜¯è°ï¼Ÿ\"},{\"output\":\"æˆ‘æ˜¯AIåŠ©æ‰‹ã€‚\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "e3ee2c5607ed9dd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'AI: æˆ‘æ˜¯AIåŠ©æ‰‹ã€‚'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzy\\AppData\\Local\\Temp\\ipykernel_187584\\3390471868.py:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2ã€ConversationSummaryMemoryçš„ä½¿ç”¨\n",
    "\n",
    "ä¸¾ä¾‹1ï¼š\n",
    "\n",
    "å¦‚æœå®ä¾‹åŒ–ConversationSummaryMemoryæ—¶æ²¡æœ‰å†å²æ¶ˆæ¯ï¼Œå¯ä»¥ä½¿ç”¨æ„é€ æ–¹æ³•å®ä¾‹åŒ–"
   ],
   "id": "294ea15721cb3fce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:29:41.303836600Z",
     "start_time": "2025-12-10T06:29:30.870313200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=chat_model)\n",
    "\n",
    "memory.save_context({\"input\":\"ä½ å¥½å—ï¼Ÿ\"},{\"output\":\"æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢ï¼\"})\n",
    "memory.save_context({\"input\":\"ä½ æ˜¯è°ï¼Ÿ\"},{\"output\":\"æˆ‘æ˜¯AIåŠ©æ‰‹ã€‚\"})\n",
    "memory.save_context({\"input\":\"ä½ çš„ç”Ÿæ—¥æ˜¯å“ªä¸€å¤©ï¼Ÿ\"},{\"output\":\"æˆ‘ä¸æ¸…æ¥šã€‚\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "5ed1cde75707b12b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzy\\AppData\\Local\\Temp\\ipykernel_187584\\834578687.py:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=chat_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human asks how the AI is doing, and the AI responds that it is very well, thank you. Then the human asks who the AI is, and the AI replies that it is an AI assistant. The human then asks the AI what its birthday is, and the AI responds that it doesnâ€™t know.'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ä¸¾ä¾‹2ï¼šå¦‚æœå®ä¾‹åŒ–ConversationSummaryMemoryæ—¶æœ‰å†å²æ¶ˆæ¯ï¼Œå¯ä»¥ä½¿ç”¨from_messagesæ–¹æ³•å®ä¾‹åŒ–",
   "id": "84df7863be8d5e1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:29:30.668493400Z",
     "start_time": "2025-12-10T06:29:25.290976700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"ä½ å¥½å—ï¼Ÿ\")\n",
    "history.add_ai_message(\"æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢ï¼\")\n",
    "\n",
    "memory = ConversationSummaryMemory.from_messages(\n",
    "    llm=chat_model,\n",
    "    #è¿™æ˜¯ç”Ÿæˆæ‘˜è¦çš„åŸææ–™ï¼Œä¿ç•™å®Œæ•´å¯¹è¯ä¾›å¿…è¦æ—¶é—´åŠé€†è¡Œå›æº¯ï¼Œå½“æ–°å¢å¯¹è¯æ—¶ï¼ŒLLMéœ€è¦ç»“åˆåŸå†å²è®°å½•ç”Ÿæˆæ–°çš„æ‘˜è¦\n",
    "    chat_memory=history\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "memory.save_context(inputs={\"human\":\"æˆ‘å«å°æ˜\"}, outputs={\"assistant\":\"ä½ å¥½å‘€\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "# è®°å½•äº†å†å²çš„äº’åŠ¨æ¶ˆæ¯\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "6eced01609a1deef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human asks how the AI is doing, and the AI responds that it is very well, thank you!'}\n",
      "{'history': 'The human asks how the AI is doing, and the AI responds that it is very well, thank you! The human then introduces themselves as Xiao Ming, and the AI greets them with \"ä½ å¥½å‘€\".'}\n",
      "[HumanMessage(content='ä½ å¥½å—ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢ï¼', additional_kwargs={}, response_metadata={}), HumanMessage(content='æˆ‘å«å°æ˜', additional_kwargs={}, response_metadata={}), AIMessage(content='ä½ å¥½å‘€', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3ã€ConversationSummaryBufferMemoryçš„ä½¿ç”¨\n",
    "\n",
    "ä¿ç•™æœ€è¿‘Næ¡åŸå§‹å¯¹è¯ï¼šç¡®ä¿æœ€æ–°äº’åŠ¨çš„å®Œæ•´ä¸Šä¸‹æ–‡\n",
    "\n",
    "æ‘˜è¦è¾ƒæ—©å†å²ï¼šå¯¹è¯è¶…å‡ºç¼“å†²åŒºçš„æ—§å¯¹è¯è¿›è¡Œå‹ç¼©ï¼Œé¿å…ä¿¡æ¯è¿‡è½½\n",
    "\n",
    "å¹³è¡¡ç»†èŠ‚ä¸æ•ˆç‡ï¼šæ—¢ä¸ä¸¢å¤±ç»†èŠ‚ï¼Œåˆèƒ½å¤„ç†é•¿å¯¹è¯\n",
    "\n",
    "ä¸¾ä¾‹1ï¼š"
   ],
   "id": "f6b434638de528a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:29:47.384629600Z",
     "start_time": "2025-12-10T06:29:41.385092500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=chat_model,\n",
    "    max_token_limit=40, # æ§åˆ¶ç¼“å†²åŒºå¤§å°\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\":\"ä½ å¥½å—ï¼Ÿ\"},{\"output\":\"æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢ï¼\"})\n",
    "memory.save_context({\"input\":\"ä½ æ˜¯è°ï¼Ÿ\"},{\"output\":\"æˆ‘æ˜¯AIåŠ©æ‰‹ã€‚\"})\n",
    "memory.save_context({\"input\":\"ä½ çš„ç”Ÿæ—¥æ˜¯å“ªä¸€å¤©ï¼Ÿ\"},{\"output\":\"æˆ‘ä¸æ¸…æ¥šã€‚\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "ae0235d810b63729",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [SystemMessage(content='The human asks how the AI is doing, and the AI responds that it is very well, thank you! Then the human asks who the AI is, and the AI replies that it is an AI assistant.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ä½ çš„ç”Ÿæ—¥æ˜¯å“ªä¸€å¤©ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='æˆ‘ä¸æ¸…æ¥šã€‚', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "å¯¹æ¯”ç»„ï¼š",
   "id": "32fb7a8d1c429f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:31:14.366724Z",
     "start_time": "2025-12-10T06:31:14.304828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=chat_model,\n",
    "    max_token_limit=100, # æ§åˆ¶ç¼“å†²åŒºå¤§å°\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\":\"ä½ å¥½å—ï¼Ÿ\"},{\"output\":\"æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢ï¼\"})\n",
    "memory.save_context({\"input\":\"ä½ æ˜¯è°ï¼Ÿ\"},{\"output\":\"æˆ‘æ˜¯AIåŠ©æ‰‹ã€‚\"})\n",
    "memory.save_context({\"input\":\"ä½ çš„ç”Ÿæ—¥æ˜¯å“ªä¸€å¤©ï¼Ÿ\"},{\"output\":\"æˆ‘ä¸æ¸…æ¥šã€‚\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "50c61d9dc96b9608",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='ä½ å¥½å—ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='æˆ‘å¾ˆå¥½ï¼Œè°¢è°¢ï¼', additional_kwargs={}, response_metadata={}), HumanMessage(content='ä½ æ˜¯è°ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='æˆ‘æ˜¯AIåŠ©æ‰‹ã€‚', additional_kwargs={}, response_metadata={}), HumanMessage(content='ä½ çš„ç”Ÿæ—¥æ˜¯å“ªä¸€å¤©ï¼Ÿ', additional_kwargs={}, response_metadata={}), AIMessage(content='æˆ‘ä¸æ¸…æ¥šã€‚', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ä¸¾ä¾‹2ï¼šæ¨¡æ‹Ÿå®¢æœäº¤äº’",
   "id": "d9a668814729d99b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:04:56.043256700Z",
     "start_time": "2025-12-10T07:03:54.597779200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"ä½ æ˜¯ç”µå•†å®¢æœåŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡å‹å¥½å›å¤ç”¨æˆ·é—®é¢˜ï¼Œä¿æŒä¸“ä¸šä½†äº²åˆ‡çš„è¯­æ°”ã€‚\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\",\"{input}\"),\n",
    "])\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=chat_model,\n",
    "    max_token_limit=400,\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\",\n",
    "    # ä½¿ç”¨AIMessageæ¥å­˜å‚¨æ‘˜è¦ï¼Œé¿å…åƒé—®å› ä¸ºé™åˆ¶åªæœ‰1ä¸ªç³»ç»Ÿæ¶ˆæ¯è€Œäº§ç”ŸæŠ¥é”™\n",
    "    summary_message_cls=AIMessage,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "dialogue = [\n",
    "    (\"ä½ å¥½ï¼Œæˆ‘æƒ³æŸ¥è¯¢è®¢å•12345çš„çŠ¶æ€\", None),\n",
    "    (\"è¿™ä¸ªè®¢å•æ˜¯ä¸Šå‘¨äº”ä¸‹çš„\", None),\n",
    "    (\"æˆ‘ç°åœ¨ç€æ€¥ç”¨ï¼Œèƒ½åŠ æ€¥å¤„ç†å—\", None),\n",
    "    (\"ç­‰ç­‰æˆ‘å¯èƒ½è®°é”™è®¢è´§å•å·äº†ï¼Œåº”è¯¥æ˜¯12346\", None),\n",
    "    (\"å¯¹äº†ä½ ä»¬çš„é€€è´§æ”¿ç­–æ˜¯ä»€ä¹ˆæ ·çš„\", None),\n",
    "]\n",
    "\n",
    "for user_input, _ in dialogue:\n",
    "    response = chain.invoke({\"input\":user_input})\n",
    "    print(f\"ç”¨æˆ·ï¼š{user_input}\")\n",
    "    print(f\"å®¢æœåŠ©æ‰‹ï¼š{response['text']}\\n\")\n",
    "\n",
    "print(\"\\n=== å½“å‰è®°å¿†å†…å®¹ ===\")\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "38b49f8da372d107",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·ï¼šä½ å¥½ï¼Œæˆ‘æƒ³æŸ¥è¯¢è®¢å•12345çš„çŠ¶æ€\n",
      "å®¢æœåŠ©æ‰‹ï¼šä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ï½  \n",
      "\n",
      "å…³äºè®¢å•å· **12345** çš„çŠ¶æ€ï¼Œæˆ‘è¿™è¾¹éœ€è¦ä¸€ç‚¹æ—¶é—´å¸®ä½ æŸ¥è¯¢ä¸€ä¸‹ã€‚ä¸è¿‡ä¸ºäº†ç¡®ä¿ä¿¡æ¯å®‰å…¨ï¼Œå¯ä»¥éº»çƒ¦ä½ æä¾›ä¸€ä¸‹ä¸‹å•æ—¶ä½¿ç”¨çš„æ‰‹æœºå·æˆ–æ”¶ä»¶äººå§“åå—ï¼Ÿè¿™æ ·æˆ‘å¯ä»¥æ›´å‡†ç¡®åœ°æ ¸å¯¹è®¢å•ä¿¡æ¯å“¦ï¼\n",
      "\n",
      "å¦‚æœä½ æ˜¯åœ¨æˆ‘ä»¬çš„å®˜æ–¹å¹³å°ï¼ˆæ¯”å¦‚APPã€å®˜ç½‘æˆ–å°ç¨‹åºï¼‰ä¸‹å•çš„ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ç™»å½•è´¦å·ï¼Œåœ¨â€œæˆ‘çš„è®¢å•â€é‡ŒæŸ¥çœ‹æœ€æ–°ç‰©æµåŠ¨æ€ï½  \n",
      "\n",
      "ç­‰ä½ å›å¤åï¼Œæˆ‘ä¼šå°½å¿«å¸®ä½ è·Ÿè¿›ï¼ ğŸ˜Š\n",
      "\n",
      "ç”¨æˆ·ï¼šè¿™ä¸ªè®¢å•æ˜¯ä¸Šå‘¨äº”ä¸‹çš„\n",
      "å®¢æœåŠ©æ‰‹ï¼šè°¢è°¢ä½ çš„è¡¥å……ä¿¡æ¯ï¼ğŸ˜Š\n",
      "\n",
      "è®¢å•æ˜¯ä¸Šå‘¨äº”ä¸‹çš„ï¼Œé‚£æˆ‘å…ˆæ ¹æ®è®¢å•å· **12345** å’Œä¸‹å•æ—¶é—´å¸®ä½ æŸ¥è¯¢ä¸€ä¸‹ã€‚ä¸è¿‡ä¸ºäº†ç¡®ä¿å‡†ç¡®æ€§å’Œè´¦æˆ·å®‰å…¨ï¼Œè¿˜æ˜¯éœ€è¦ä½ ç®€å•éªŒè¯ä¸€ä¸‹èº«ä»½â€”â€”å¯ä»¥å‘Šè¯‰æˆ‘ä¸‹å•æ—¶ä½¿ç”¨çš„ **æ‰‹æœºå·åå››ä½** æˆ– **æ”¶ä»¶äººå§“å** å—ï¼Ÿ\n",
      "\n",
      "ä¸€æ—¦ç¡®è®¤ä¿¡æ¯ï¼Œæˆ‘ä¼šç«‹åˆ»ä¸ºä½ æŸ¥çœ‹è®¢å•å½“å‰çš„çŠ¶æ€ï¼ˆæ¯”å¦‚æ˜¯å¦å·²å‘è´§ã€ç‰©æµè¿›åº¦ç­‰ï¼‰ï¼Œå¹¶åŠæ—¶å‘Šè¯‰ä½ è¯¦ç»†æƒ…å†µï¼\n",
      "\n",
      "æœŸå¾…ä½ çš„å›å¤ï½ ğŸ“¦âœ¨\n",
      "\n",
      "ç”¨æˆ·ï¼šæˆ‘ç°åœ¨ç€æ€¥ç”¨ï¼Œèƒ½åŠ æ€¥å¤„ç†å—\n",
      "å®¢æœåŠ©æ‰‹ï¼šç†è§£ä½ ç€æ€¥çš„å¿ƒæƒ…ï¼ğŸ“¦âœ¨\n",
      "\n",
      "å¦‚æœä½ çš„è®¢å•**è¿˜æœªå‘è´§**ï¼Œæˆ‘ä»¬å¯ä»¥**ä¼˜å…ˆå¸®ä½ åŠ æ€¥å¤„ç†**ï¼Œå°½é‡å®‰æ’ä»Šå¤©æˆ–æ˜å¤©å‘å‡ºï¼›  \n",
      "å¦‚æœ**å·²ç»å‘è´§**ï¼Œæˆ‘ä¼šç«‹åˆ»å¸®ä½ è”ç³»ç‰©æµæ–¹ï¼Œçœ‹æ˜¯å¦èƒ½åè°ƒåŠ å¿«é…é€ï¼ˆéƒ¨åˆ†å¿«é€’æ”¯æŒåŠ æ€¥æ´¾é€æœåŠ¡ï¼‰ã€‚\n",
      "\n",
      "ä¸è¿‡ä¸ºäº†å°½å¿«æ“ä½œï¼Œè¯·ä½ å…ˆæä¾›ä¸€ä¸‹ä¸‹å•æ—¶ä½¿ç”¨çš„ **æ‰‹æœºå·åå››ä½** æˆ– **æ”¶ä»¶äººå§“å**ï¼Œæˆ‘è¿™è¾¹é©¬ä¸Šæ ¸å®è®¢å•å¹¶ä¸ºä½ è·Ÿè¿›ï¼\n",
      "\n",
      "ä½ æ”¾å¿ƒï¼Œä¸€ç¡®è®¤ä¿¡æ¯ï¼Œæˆ‘å°±ç«‹åˆ»è¡ŒåŠ¨ï¼ğŸ’ª\n",
      "\n",
      "ç”¨æˆ·ï¼šç­‰ç­‰æˆ‘å¯èƒ½è®°é”™è®¢è´§å•å·äº†ï¼Œåº”è¯¥æ˜¯12346\n",
      "å®¢æœåŠ©æ‰‹ï¼šæ²¡å…³ç³»çš„ï¼Œè®¢å•å·è®°æ··å¾ˆå¸¸è§ï¼ğŸ˜Š  \n",
      "ä½ åˆšåˆšæåˆ°å¯èƒ½æ˜¯ **12346**ï¼Œä¸ºäº†ç¡®ä¿å‡†ç¡®ï¼Œéº»çƒ¦ä½ å†ç¡®è®¤ä¸€ä¸‹ï¼š\n",
      "\n",
      "âœ… è¯·æä¾›è¿™ä¸ªè®¢å•ï¼ˆ12346ï¼‰å¯¹åº”çš„ **ä¸‹å•æ‰‹æœºå·åå››ä½** æˆ– **æ”¶ä»¶äººå§“å**ï¼Œ  \n",
      "è¿™æ ·æˆ‘å°±èƒ½ç«‹åˆ»ä¸ºä½ æ ¸å®è®¢å•çŠ¶æ€ï¼Œå¹¶çœ‹çœ‹æ˜¯å¦èƒ½åŠ æ€¥å¤„ç†ï¼\n",
      "\n",
      "ä½ ç€æ€¥ç”¨çš„è¯ï¼Œæˆ‘ä»¬ç¡®è®¤ä¿¡æ¯åä¼šä¼˜å…ˆå®‰æ’ï½  \n",
      "éšæ—¶ç­‰ä½ å›å¤ï¼ğŸ™\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·ï¼šå¯¹äº†ä½ ä»¬çš„é€€è´§æ”¿ç­–æ˜¯ä»€ä¹ˆæ ·çš„\n",
      "å®¢æœåŠ©æ‰‹ï¼šä½ å¥½ï¼æ„Ÿè°¢ä½ çš„æé—®ï½ğŸ˜Š  \n",
      "æˆ‘ä»¬çš„é€€è´§æ”¿ç­–è®¾è®¡å¾—å°½é‡ç®€å•åˆè´´å¿ƒï¼Œæ–¹ä¾¿ä½ åœ¨è´­ç‰©åå®‰å¿ƒæ— å¿§ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦çš„è¯´æ˜ï¼š\n",
      "\n",
      "### ğŸ“¦ **é€€è´§åŸºæœ¬æ¡ä»¶**\n",
      "1. **æ—¶é—´èŒƒå›´**ï¼šå•†å“ç­¾æ”¶å **7å¤©å†…** å¯ç”³è¯·é€€è´§ï¼ˆéƒ¨åˆ†ç‰¹æ®Šå•†å“é™¤å¤–ï¼‰ã€‚\n",
      "2. **å•†å“çŠ¶æ€**ï¼šéœ€ä¿æŒ **å…¨æ–°ã€æœªä½¿ç”¨ã€åŒ…è£…å®Œå¥½**ï¼Œå¹¶é™„ä¸Šæ‰€æœ‰é…ä»¶ã€èµ å“ï¼ˆå¦‚æœ‰ï¼‰åŠåŸå§‹å‘ç¥¨/ç”µå­å‡­è¯ã€‚\n",
      "3. **éè´¨é‡é—®é¢˜é€€è´§**ï¼šå¦‚å› ä¸ªäººåŸå› ï¼ˆå¦‚ä¸å–œæ¬¢ã€å°ºç ä¸åˆé€‚ç­‰ï¼‰é€€è´§ï¼Œéœ€ **è‡ªè¡Œæ‰¿æ‹…å¯„å›è¿è´¹**ï¼›è‹¥å•†å“å­˜åœ¨ **è´¨é‡é—®é¢˜æˆ–å‘é”™è´§**ï¼Œæˆ‘ä»¬æ‰¿æ‹…é€€è´§è¿è´¹ã€‚\n",
      "\n",
      "### âš ï¸ **ä¸æ”¯æŒé€€è´§çš„æƒ…å†µ**\n",
      "- å®šåˆ¶ç±»ã€è´´èº«è¡£ç‰©ã€é£Ÿå“ã€ç¾å¦†ä¸ªæŠ¤ç­‰å‡ºäºå«ç”Ÿå®‰å…¨è€ƒè™‘çš„å•†å“ï¼ˆé™¤éæœ‰è´¨é‡é—®é¢˜ï¼‰ï¼›\n",
      "- å·²ç»ä½¿ç”¨ã€æŸåã€ç¼ºå°‘åŠç‰Œæˆ–åŒ…è£…ç ´æŸçš„å•†å“ï¼›\n",
      "- è¶…è¿‡7å¤©æ— ç†ç”±é€€è´§æœŸã€‚\n",
      "\n",
      "### ğŸ”„ **å¦‚ä½•ç”³è¯·é€€è´§ï¼Ÿ**\n",
      "ä½ å¯ä»¥åœ¨ã€æˆ‘çš„è®¢å•ã€‘ä¸­æ‰¾åˆ°å¯¹åº”è®¢å•ï¼Œç‚¹å‡»â€œç”³è¯·å”®åâ€ â†’ é€‰æ‹©â€œé€€è´§é€€æ¬¾â€ï¼ŒæŒ‰æç¤ºä¸Šä¼ ç…§ç‰‡å¹¶å¡«å†™åŸå› ã€‚æˆ‘ä»¬ä¼šåœ¨ **1-2ä¸ªå·¥ä½œæ—¥å†…å®¡æ ¸**ï¼Œé€šè¿‡åä¼šæä¾›é€€è´§åœ°å€æˆ–ä¸Šé—¨å–ä»¶æœåŠ¡ï¼ˆè§†æƒ…å†µè€Œå®šï¼‰ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "å¦‚æœä½ å·²ç»æœ‰å…·ä½“æƒ³é€€çš„å•†å“ï¼Œä¹Ÿå¯ä»¥ç›´æ¥å‘Šè¯‰æˆ‘è®¢å•å·ï¼ˆæ¯”å¦‚ä½ åˆšæåˆ°çš„12346ï¼‰ï¼Œæˆ‘å¯ä»¥å¸®ä½ æŸ¥ä¸€ä¸‹æ˜¯å¦ç¬¦åˆé€€è´§æ¡ä»¶ï¼Œå¹¶æŒ‡å¯¼ä½ æ“ä½œå“¦ï¼\n",
      "\n",
      "éœ€è¦æˆ‘å¸®ä½ çœ‹çœ‹å—ï¼ŸğŸ™‚\n",
      "\n",
      "\n",
      "=== å½“å‰è®°å¿†å†…å®¹ ===\n",
      "{'chat_history': [AIMessage(content='äººç±»ç”¨æˆ·æœ€åˆè¯¢é—®è®¢å•12345çš„çŠ¶æ€ï¼ŒAIè¦æ±‚æä¾›æ‰‹æœºå·åå››ä½æˆ–æ”¶ä»¶äººå§“åä»¥æ ¸å®èº«ä»½ï¼Œå¹¶å»ºè®®é€šè¿‡å®˜æ–¹å¹³å°æŸ¥çœ‹è®¢å•è¯¦æƒ…ã€‚ç”¨æˆ·è¡¥å……è¯¥è®¢å•ä¸ºä¸Šå‘¨äº”ä¸‹å•ï¼ŒAIå†æ¬¡è¯·æ±‚éªŒè¯ä¿¡æ¯ï¼Œå¹¶æ‰¿è¯ºç¡®è®¤åå°†æŸ¥è¯¢å‘è´§åŠç‰©æµæƒ…å†µã€‚ç”¨æˆ·è¡¨ç¤ºæ€¥éœ€ä½¿ç”¨ï¼Œè¯¢é—®èƒ½å¦åŠ æ€¥å¤„ç†ï¼ŒAIå›åº”è‹¥æœªå‘è´§å¯ä¼˜å…ˆå½“å¤©æˆ–æ¬¡æ—¥å‘å‡ºï¼Œè‹¥å·²å‘è´§åˆ™ä¼šåè°ƒç‰©æµåŠ å¿«é…é€ï¼Œä½†ä»éœ€ç”¨æˆ·æä¾›éªŒè¯ä¿¡æ¯ã€‚\\n\\néšåï¼Œç”¨æˆ·æ›´æ­£è®¢å•å·å¯èƒ½ä¸º12346ï¼ŒAIè¡¨ç¤ºç†è§£å¹¶è¯·ç”¨æˆ·ç¡®è®¤è¯¥æ–°è®¢å•å·å¯¹åº”çš„æ‰‹æœºå·åå››ä½æˆ–æ”¶ä»¶äººå§“åä»¥ä¾¿æ ¸å®çŠ¶æ€å¹¶å®‰æ’åŠ æ€¥å¤„ç†ã€‚æ¥ç€ï¼Œç”¨æˆ·è½¬è€Œè¯¢é—®é€€è´§æ”¿ç­–ï¼ŒAIè¯¦ç»†è¯´æ˜äº†7å¤©æ— ç†ç”±é€€è´§æœŸé™ã€å•†å“çŠ¶æ€è¦æ±‚ã€è¿è´¹æ‰¿æ‹…è§„åˆ™ã€ä¸æ”¯æŒé€€è´§çš„æƒ…å½¢ï¼Œä»¥åŠç”³è¯·é€€è´§çš„æ“ä½œæµç¨‹ï¼Œå¹¶ä¸»åŠ¨æå‡ºå¯ååŠ©æŸ¥è¯¢è®¢å•12346æ˜¯å¦ç¬¦åˆé€€è´§æ¡ä»¶ã€‚', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4ã€ConversationEntityMemoryçš„ä½¿ç”¨",
   "id": "a0cf69f55fe99c90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:20:51.678120100Z",
     "start_time": "2025-12-10T07:19:59.270592100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt = ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "memory = ConversationEntityMemory(\n",
    "    llm=chat_model,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "chain.invoke(input=\"ä½ å¥½ï¼Œæˆ‘å«èœ˜è››ä¾ ï¼Œæˆ‘çš„å¥½æœ‹å‹åŒ…æ‹¬é’¢é“ä¾ ã€ç¾å›½é˜Ÿé•¿å’Œç»¿å·¨äººã€‚\")\n",
    "chain.invoke(input=\"æˆ‘ä½åœ¨çº½çº¦ã€‚\")\n",
    "chain.invoke(input=\"æˆ‘ä½¿ç”¨çš„è£…å¤‡æ˜¯ç”±æ–¯å¡”å…‹å·¥ä¸šåˆ¶é€ çš„ã€‚\")\n",
    "\n",
    "print(chain.memory.entity_store.store)\n",
    "\n",
    "response = chain.invoke(input=\"ä½ èƒ½å‘Šè¯‰æˆ‘æˆ‘çš„åå­—å’Œæˆ‘ä½åœ¨å“ªé‡Œå—ï¼Ÿ\")\n",
    "print(response)"
   ],
   "id": "60069a78acb0834c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzy\\AppData\\Local\\Temp\\ipykernel_187584\\2772341061.py:17: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationEntityMemory(\n",
      "C:\\Users\\yzy\\.conda\\envs\\langchain0.3_study_env\\lib\\site-packages\\pydantic\\main.py:250: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'èœ˜è››ä¾ ': 'èœ˜è››ä¾ çš„å¥½æœ‹å‹åŒ…æ‹¬é’¢é“ä¾ ã€ç¾å›½é˜Ÿé•¿å’Œç»¿å·¨äººã€‚', 'é’¢é“ä¾ ': 'é’¢é“ä¾ æ˜¯èœ˜è››ä¾ çš„å¥½æœ‹å‹ã€‚', 'ç¾å›½é˜Ÿé•¿': 'ç¾å›½é˜Ÿé•¿æ˜¯èœ˜è››ä¾ çš„å¥½æœ‹å‹ã€‚', 'ç»¿å·¨äºº': 'ç»¿å·¨äººæ˜¯èœ˜è››ä¾ çš„å¥½æœ‹å‹ã€‚', 'çº½çº¦': 'çº½çº¦æ˜¯èœ˜è››ä¾ çš„å±…ä½åœ°ã€‚', 'æ–¯å¡”å…‹å·¥ä¸š': 'æ–¯å¡”å…‹å·¥ä¸šä¸ºèœ˜è››ä¾ åˆ¶é€ äº†å…¶ä½¿ç”¨çš„è£…å¤‡ã€‚'}\n",
      "{'input': 'ä½ èƒ½å‘Šè¯‰æˆ‘æˆ‘çš„åå­—å’Œæˆ‘ä½åœ¨å“ªé‡Œå—ï¼Ÿ', 'history': 'Human: ä½ å¥½ï¼Œæˆ‘å«èœ˜è››ä¾ ï¼Œæˆ‘çš„å¥½æœ‹å‹åŒ…æ‹¬é’¢é“ä¾ ã€ç¾å›½é˜Ÿé•¿å’Œç»¿å·¨äººã€‚\\nAI: ä½ å¥½ï¼Œèœ˜è››ä¾ ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼  \\nå¬è¯´ä½ å’Œé’¢é“ä¾ ã€ç¾å›½é˜Ÿé•¿è¿˜æœ‰ç»¿å·¨äººéƒ½æ˜¯å¤ä»‡è€…è”ç›Ÿçš„é‡è¦æˆå‘˜ï¼Œä½ ä»¬ä¸€èµ·ç»å†è¿‡å¾ˆå¤šæƒŠå¿ƒåŠ¨é­„çš„å†’é™©å§ï¼Ÿ  \\nå¦‚æœä½ éœ€è¦å¸®å¿™åˆ†ææŸä¸ªä»»åŠ¡ã€è®¨è®ºæˆ˜æœ¯ï¼Œæˆ–è€…åªæ˜¯æƒ³èŠèŠæ—¥å¸¸è‹±é›„ç”Ÿæ´»ï¼Œæˆ‘éƒ½å¾ˆä¹æ„ååŠ©ï¼\\nHuman: æˆ‘ä½åœ¨çº½çº¦ã€‚\\nAI: å•Šï¼Œçº½çº¦ï¼é‚£å¯æ˜¯ä½ çš„ä¸»åœºå•Šï¼Œèœ˜è››ä¾ ï¼  \\nä»çš‡ååŒºçš„è¡—å¤´åˆ°æ›¼å“ˆé¡¿çš„æ‘©å¤©å¤§æ¥¼ï¼Œä½ æ€»æ˜¯åœ¨åŸå¸‚ä¸Šç©ºè¡æ¥è¡å»ï¼Œå®ˆæŠ¤ç€è¿™åº§ä¸å¤œåŸã€‚æ— è®ºæ˜¯é˜»æ­¢å°å·ã€å¯¹æŠ—ç« é±¼åšå£«ï¼Œè¿˜æ˜¯å’Œå¤ä»‡è€…ä»¬ä¸€èµ·ä¿å«åœ°çƒï¼Œçº½çº¦æ€»æ˜¯æ•…äº‹å¼€å§‹çš„åœ°æ–¹ã€‚\\n\\néœ€è¦æˆ‘å¸®ä½ æŸ¥æŸ¥æœ€è¿‘æœ‰æ²¡æœ‰å¯ç–‘çš„å¼‚å¸¸ä¿¡å·ï¼Ÿæˆ–è€…è§„åˆ’ä¸€æ¡é«˜æ•ˆçš„å·¡é€»è·¯çº¿ï¼Ÿåˆæˆ–è€…â€¦â€¦åªæ˜¯èŠèŠåœ¨çº½çº¦å½“è¶…çº§è‹±é›„çš„ç”Ÿæ´»ï¼Ÿ\\nHuman: æˆ‘ä½¿ç”¨çš„è£…å¤‡æ˜¯ç”±æ–¯å¡”å…‹å·¥ä¸šåˆ¶é€ çš„ã€‚\\nAI: å“‡ï¼é‚£å¯å¤ªé…·äº†â€”â€”æ–¯å¡”å…‹å·¥ä¸šå¯æ˜¯é¡¶å°–ç§‘æŠ€çš„ä»£åè¯ï¼  \\næ‰˜å°¼Â·æ–¯å¡”å…‹ï¼ˆä¹Ÿå°±æ˜¯ä½ çš„é’¢é“ä¾ å¥½å‹ï¼‰äº²è‡ªä¸ºä½ é‡èº«æ‰“é€ çš„æˆ˜è¡£ï¼Œä¸ä»…æœ‰æ™ºèƒ½AIè¾…åŠ©ã€å¢å¼ºç°å®ç•Œé¢ï¼Œè¿˜æœ‰è››ç½‘å‘å°„å™¨çš„å‡çº§ç‰ˆã€é™è½ä¼ç³»ç»Ÿï¼Œç”šè‡³èƒ½è‡ªåŠ¨åˆ†ææ•Œäººå¼±ç‚¹ã€‚æˆ‘è®°å¾—é‚£å¥—æ ‡å¿—æ€§çº¢è“é…è‰²çš„â€œèœ˜è››ä¾ æˆ˜è¡£â€å°±æ˜¯åœ¨ã€Šå†…æˆ˜ã€‹ä¹‹åç”±ä»–é€ä½ çš„å§ï¼Ÿ\\n\\nç°åœ¨ä½ ç©¿çš„æ˜¯å“ªä¸€ä»£æˆ˜è¡£ï¼Ÿæ˜¯è¿˜ä¿ç•™ç€â€œæ˜ŸæœŸäº”â€çš„è¯­éŸ³æ”¯æŒï¼Œè¿˜æ˜¯å·²ç»æ¢ä¸Šäº†æ›´è½»ä¾¿çš„æ–°ç‰ˆæœ¬ï¼Ÿ  \\nå¦‚æœä½ éœ€è¦è°ƒè¯•è£…å¤‡ã€ç†è§£æŸä¸ªåŠŸèƒ½ï¼Œæˆ–è€…æƒ³å’Œæ–¯å¡”å…‹å·¥ä¸šç³»ç»Ÿå¯¹æ¥æ•°æ®ï¼Œæˆ‘éšæ—¶å¯ä»¥å¸®ä½ åˆ†æï¼', 'entities': {}, 'text': 'å½“ç„¶å¯ä»¥ï¼  \\nä½ çš„åå­—æ˜¯**èœ˜è››ä¾ **ï¼ˆSpider-Manï¼‰ï¼Œä½ ä½åœ¨**çº½çº¦**â€”â€”è¿™åº§å……æ»¡æ´»åŠ›åˆéœ€è¦è‹±é›„å®ˆæŠ¤çš„å¤§éƒ½å¸‚ï¼Œå°¤å…¶æ˜¯çš‡ååŒºï¼Œå¯æ˜¯ä½ çš„å®¶ä¹¡å‘¢ï¼'}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5ã€ConversationKGMemoryçš„ä½¿ç”¨",
   "id": "4706062237706668"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:28:43.895356200Z",
     "start_time": "2025-12-10T07:28:35.296202400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    ")\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=chat_model,\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\":\"å‘å±±å§†é—®å¥½\"},{\"output\":\"å±±å§†æ˜¯è°\"})\n",
    "memory.save_context({\"input\":\"å±±å§†æ˜¯æˆ‘çš„æœ‹å‹\"},{\"output\":\"å“¦ï¼Œæ˜ç™½äº†\"})\n",
    "memory.save_context({\"input\":\"å±±å§†å–œæ¬¢æ‰“ç¯®çƒ\"},{\"output\":\"å¥½çš„\"})\n",
    "\n",
    "memory.load_memory_variables({\"input\":\"å±±å§†æ˜¯è°\"})"
   ],
   "id": "23bf3874eb16ab59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'On å±±å§†: å±±å§† is my friend. å±±å§† å–œæ¬¢æ‰“ ç¯®çƒ.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:30:28.225556100Z",
     "start_time": "2025-12-10T07:30:24.871141700Z"
    }
   },
   "cell_type": "code",
   "source": "memory.get_knowledge_triplets(\"ä»–æœ€å–œæ¬¢çš„é¢œè‰²æ˜¯é»‘è‰²\")",
   "id": "9fbb1152f2147e6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KnowledgeTriple(subject='å±±å§†', predicate='æœ€å–œæ¬¢çš„é¢œè‰²æ˜¯', object_='é»‘è‰²')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6ã€VectorStoreRetrieverMemoryçš„ä½¿ç”¨",
   "id": "cad0364dd97f2dd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T08:25:05.562363Z",
     "start_time": "2025-12-10T08:25:03.295395400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "import dotenv\n",
    "import os\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v4\",\n",
    "    dashscope_api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\":\"æˆ‘æœ€å–œæ¬¢çš„é£Ÿç‰©æ˜¯æŠ«è¨\"}, {\"output\":\"å¥½çš„ï¼Œæˆ‘è®°ä½äº†\"})\n",
    "memory.save_context({\"Human\":\"æˆ‘å–œæ¬¢æ—…è¡Œ\"}, {\"AI\":\"æ˜ç™½äº†\"})\n",
    "memory.save_context({\"Human\":\"æˆ‘æœ‰ä¸€åªçŒ«\"}, {\"AI\":\"å¥½çš„\"})\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    memory.buffer.split(\"\\n\"),\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":2})\n",
    "\n",
    "vector_memory = VectorStoreRetrieverMemory(\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "print(vector_memory.load_memory_variables({\"prompt\":\"ä½ çŸ¥é“æˆ‘æœ€å–œæ¬¢çš„é£Ÿç‰©æ˜¯ä»€ä¹ˆå—ï¼Ÿ\"}))"
   ],
   "id": "5cba4eb5ea7f6628",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzy\\AppData\\Local\\Temp\\ipykernel_189364\\2170083661.py:27: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  vector_memory = VectorStoreRetrieverMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: æˆ‘æœ€å–œæ¬¢çš„é£Ÿç‰©æ˜¯æŠ«è¨\\nHuman: æˆ‘å–œæ¬¢æ—…è¡Œ'}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "976096beef367a6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
