{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1、ConversationTokenMemory简介\n",
    "\n",
    "举例1："
   ],
   "id": "c66baef6ba0a8e1e"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T06:29:41.374892800Z",
     "start_time": "2025-12-10T06:29:41.327682100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory, ConversationSummaryBufferMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=chat_model,\n",
    "    max_token_limit=20\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\":\"你好吗？\"},{\"output\":\"我很好，谢谢！\"})\n",
    "memory.save_context({\"input\":\"你是谁？\"},{\"output\":\"我是AI助手。\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "e3ee2c5607ed9dd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'AI: 我是AI助手。'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzy\\AppData\\Local\\Temp\\ipykernel_187584\\3390471868.py:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2、ConversationSummaryMemory的使用\n",
    "\n",
    "举例1：\n",
    "\n",
    "如果实例化ConversationSummaryMemory时没有历史消息，可以使用构造方法实例化"
   ],
   "id": "294ea15721cb3fce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:29:41.303836600Z",
     "start_time": "2025-12-10T06:29:30.870313200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=chat_model)\n",
    "\n",
    "memory.save_context({\"input\":\"你好吗？\"},{\"output\":\"我很好，谢谢！\"})\n",
    "memory.save_context({\"input\":\"你是谁？\"},{\"output\":\"我是AI助手。\"})\n",
    "memory.save_context({\"input\":\"你的生日是哪一天？\"},{\"output\":\"我不清楚。\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "5ed1cde75707b12b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzy\\AppData\\Local\\Temp\\ipykernel_187584\\834578687.py:13: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=chat_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human asks how the AI is doing, and the AI responds that it is very well, thank you. Then the human asks who the AI is, and the AI replies that it is an AI assistant. The human then asks the AI what its birthday is, and the AI responds that it doesn’t know.'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2：如果实例化ConversationSummaryMemory时有历史消息，可以使用from_messages方法实例化",
   "id": "84df7863be8d5e1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:29:30.668493400Z",
     "start_time": "2025-12-10T06:29:25.290976700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"你好吗？\")\n",
    "history.add_ai_message(\"我很好，谢谢！\")\n",
    "\n",
    "memory = ConversationSummaryMemory.from_messages(\n",
    "    llm=chat_model,\n",
    "    #这是生成摘要的原材料，保留完整对话供必要时间及逆行回溯，当新增对话时，LLM需要结合原历史记录生成新的摘要\n",
    "    chat_memory=history\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "memory.save_context(inputs={\"human\":\"我叫小明\"}, outputs={\"assistant\":\"你好呀\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))\n",
    "\n",
    "# 记录了历史的互动消息\n",
    "print(memory.chat_memory.messages)"
   ],
   "id": "6eced01609a1deef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human asks how the AI is doing, and the AI responds that it is very well, thank you!'}\n",
      "{'history': 'The human asks how the AI is doing, and the AI responds that it is very well, thank you! The human then introduces themselves as Xiao Ming, and the AI greets them with \"你好呀\".'}\n",
      "[HumanMessage(content='你好吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}), HumanMessage(content='我叫小明', additional_kwargs={}, response_metadata={}), AIMessage(content='你好呀', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3、ConversationSummaryBufferMemory的使用\n",
    "\n",
    "保留最近N条原始对话：确保最新互动的完整上下文\n",
    "\n",
    "摘要较早历史：对话超出缓冲区的旧对话进行压缩，避免信息过载\n",
    "\n",
    "平衡细节与效率：既不丢失细节，又能处理长对话\n",
    "\n",
    "举例1："
   ],
   "id": "f6b434638de528a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:29:47.384629600Z",
     "start_time": "2025-12-10T06:29:41.385092500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=chat_model,\n",
    "    max_token_limit=40, # 控制缓冲区大小\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\":\"你好吗？\"},{\"output\":\"我很好，谢谢！\"})\n",
    "memory.save_context({\"input\":\"你是谁？\"},{\"output\":\"我是AI助手。\"})\n",
    "memory.save_context({\"input\":\"你的生日是哪一天？\"},{\"output\":\"我不清楚。\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "ae0235d810b63729",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [SystemMessage(content='The human asks how the AI is doing, and the AI responds that it is very well, thank you! Then the human asks who the AI is, and the AI replies that it is an AI assistant.', additional_kwargs={}, response_metadata={}), HumanMessage(content='你的生日是哪一天？', additional_kwargs={}, response_metadata={}), AIMessage(content='我不清楚。', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "对比组：",
   "id": "32fb7a8d1c429f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T06:31:14.366724Z",
     "start_time": "2025-12-10T06:31:14.304828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=chat_model,\n",
    "    max_token_limit=100, # 控制缓冲区大小\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\":\"你好吗？\"},{\"output\":\"我很好，谢谢！\"})\n",
    "memory.save_context({\"input\":\"你是谁？\"},{\"output\":\"我是AI助手。\"})\n",
    "memory.save_context({\"input\":\"你的生日是哪一天？\"},{\"output\":\"我不清楚。\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "50c61d9dc96b9608",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='你好吗？', additional_kwargs={}, response_metadata={}), AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}), HumanMessage(content='你是谁？', additional_kwargs={}, response_metadata={}), AIMessage(content='我是AI助手。', additional_kwargs={}, response_metadata={}), HumanMessage(content='你的生日是哪一天？', additional_kwargs={}, response_metadata={}), AIMessage(content='我不清楚。', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2：模拟客服交互",
   "id": "d9a668814729d99b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:04:56.043256700Z",
     "start_time": "2025-12-10T07:03:54.597779200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"你是电商客服助手，用中文友好回复用户问题，保持专业但亲切的语气。\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\",\"{input}\"),\n",
    "])\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=chat_model,\n",
    "    max_token_limit=400,\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\",\n",
    "    # 使用AIMessage来存储摘要，避免千问因为限制只有1个系统消息而产生报错\n",
    "    summary_message_cls=AIMessage,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "dialogue = [\n",
    "    (\"你好，我想查询订单12345的状态\", None),\n",
    "    (\"这个订单是上周五下的\", None),\n",
    "    (\"我现在着急用，能加急处理吗\", None),\n",
    "    (\"等等我可能记错订货单号了，应该是12346\", None),\n",
    "    (\"对了你们的退货政策是什么样的\", None),\n",
    "]\n",
    "\n",
    "for user_input, _ in dialogue:\n",
    "    response = chain.invoke({\"input\":user_input})\n",
    "    print(f\"用户：{user_input}\")\n",
    "    print(f\"客服助手：{response['text']}\\n\")\n",
    "\n",
    "print(\"\\n=== 当前记忆内容 ===\")\n",
    "print(memory.load_memory_variables({}))"
   ],
   "id": "38b49f8da372d107",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户：你好，我想查询订单12345的状态\n",
      "客服助手：你好！很高兴为你服务～  \n",
      "\n",
      "关于订单号 **12345** 的状态，我这边需要一点时间帮你查询一下。不过为了确保信息安全，可以麻烦你提供一下下单时使用的手机号或收件人姓名吗？这样我可以更准确地核对订单信息哦！\n",
      "\n",
      "如果你是在我们的官方平台（比如APP、官网或小程序）下单的，也可以直接登录账号，在“我的订单”里查看最新物流动态～  \n",
      "\n",
      "等你回复后，我会尽快帮你跟进！ 😊\n",
      "\n",
      "用户：这个订单是上周五下的\n",
      "客服助手：谢谢你的补充信息！😊\n",
      "\n",
      "订单是上周五下的，那我先根据订单号 **12345** 和下单时间帮你查询一下。不过为了确保准确性和账户安全，还是需要你简单验证一下身份——可以告诉我下单时使用的 **手机号后四位** 或 **收件人姓名** 吗？\n",
      "\n",
      "一旦确认信息，我会立刻为你查看订单当前的状态（比如是否已发货、物流进度等），并及时告诉你详细情况！\n",
      "\n",
      "期待你的回复～ 📦✨\n",
      "\n",
      "用户：我现在着急用，能加急处理吗\n",
      "客服助手：理解你着急的心情！📦✨\n",
      "\n",
      "如果你的订单**还未发货**，我们可以**优先帮你加急处理**，尽量安排今天或明天发出；  \n",
      "如果**已经发货**，我会立刻帮你联系物流方，看是否能协调加快配送（部分快递支持加急派送服务）。\n",
      "\n",
      "不过为了尽快操作，请你先提供一下下单时使用的 **手机号后四位** 或 **收件人姓名**，我这边马上核实订单并为你跟进！\n",
      "\n",
      "你放心，一确认信息，我就立刻行动！💪\n",
      "\n",
      "用户：等等我可能记错订货单号了，应该是12346\n",
      "客服助手：没关系的，订单号记混很常见！😊  \n",
      "你刚刚提到可能是 **12346**，为了确保准确，麻烦你再确认一下：\n",
      "\n",
      "✅ 请提供这个订单（12346）对应的 **下单手机号后四位** 或 **收件人姓名**，  \n",
      "这样我就能立刻为你核实订单状态，并看看是否能加急处理！\n",
      "\n",
      "你着急用的话，我们确认信息后会优先安排～  \n",
      "随时等你回复！🙏\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户：对了你们的退货政策是什么样的\n",
      "客服助手：你好！感谢你的提问～😊  \n",
      "我们的退货政策设计得尽量简单又贴心，方便你在购物后安心无忧。以下是主要的说明：\n",
      "\n",
      "### 📦 **退货基本条件**\n",
      "1. **时间范围**：商品签收后 **7天内** 可申请退货（部分特殊商品除外）。\n",
      "2. **商品状态**：需保持 **全新、未使用、包装完好**，并附上所有配件、赠品（如有）及原始发票/电子凭证。\n",
      "3. **非质量问题退货**：如因个人原因（如不喜欢、尺码不合适等）退货，需 **自行承担寄回运费**；若商品存在 **质量问题或发错货**，我们承担退货运费。\n",
      "\n",
      "### ⚠️ **不支持退货的情况**\n",
      "- 定制类、贴身衣物、食品、美妆个护等出于卫生安全考虑的商品（除非有质量问题）；\n",
      "- 已经使用、损坏、缺少吊牌或包装破损的商品；\n",
      "- 超过7天无理由退货期。\n",
      "\n",
      "### 🔄 **如何申请退货？**\n",
      "你可以在【我的订单】中找到对应订单，点击“申请售后” → 选择“退货退款”，按提示上传照片并填写原因。我们会在 **1-2个工作日内审核**，通过后会提供退货地址或上门取件服务（视情况而定）。\n",
      "\n",
      "---\n",
      "\n",
      "如果你已经有具体想退的商品，也可以直接告诉我订单号（比如你刚提到的12346），我可以帮你查一下是否符合退货条件，并指导你操作哦！\n",
      "\n",
      "需要我帮你看看吗？🙂\n",
      "\n",
      "\n",
      "=== 当前记忆内容 ===\n",
      "{'chat_history': [AIMessage(content='人类用户最初询问订单12345的状态，AI要求提供手机号后四位或收件人姓名以核实身份，并建议通过官方平台查看订单详情。用户补充该订单为上周五下单，AI再次请求验证信息，并承诺确认后将查询发货及物流情况。用户表示急需使用，询问能否加急处理，AI回应若未发货可优先当天或次日发出，若已发货则会协调物流加快配送，但仍需用户提供验证信息。\\n\\n随后，用户更正订单号可能为12346，AI表示理解并请用户确认该新订单号对应的手机号后四位或收件人姓名以便核实状态并安排加急处理。接着，用户转而询问退货政策，AI详细说明了7天无理由退货期限、商品状态要求、运费承担规则、不支持退货的情形，以及申请退货的操作流程，并主动提出可协助查询订单12346是否符合退货条件。', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4、ConversationEntityMemory的使用",
   "id": "a0cf69f55fe99c90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:20:51.678120100Z",
     "start_time": "2025-12-10T07:19:59.270592100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    ")\n",
    "\n",
    "prompt = ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "memory = ConversationEntityMemory(\n",
    "    llm=chat_model,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "chain.invoke(input=\"你好，我叫蜘蛛侠，我的好朋友包括钢铁侠、美国队长和绿巨人。\")\n",
    "chain.invoke(input=\"我住在纽约。\")\n",
    "chain.invoke(input=\"我使用的装备是由斯塔克工业制造的。\")\n",
    "\n",
    "print(chain.memory.entity_store.store)\n",
    "\n",
    "response = chain.invoke(input=\"你能告诉我我的名字和我住在哪里吗？\")\n",
    "print(response)"
   ],
   "id": "60069a78acb0834c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yzy\\AppData\\Local\\Temp\\ipykernel_187584\\2772341061.py:17: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationEntityMemory(\n",
      "C:\\Users\\yzy\\.conda\\envs\\langchain0.3_study_env\\lib\\site-packages\\pydantic\\main.py:250: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'蜘蛛侠': '蜘蛛侠的好朋友包括钢铁侠、美国队长和绿巨人。', '钢铁侠': '钢铁侠是蜘蛛侠的好朋友。', '美国队长': '美国队长是蜘蛛侠的好朋友。', '绿巨人': '绿巨人是蜘蛛侠的好朋友。', '纽约': '纽约是蜘蛛侠的居住地。', '斯塔克工业': '斯塔克工业为蜘蛛侠制造了其使用的装备。'}\n",
      "{'input': '你能告诉我我的名字和我住在哪里吗？', 'history': 'Human: 你好，我叫蜘蛛侠，我的好朋友包括钢铁侠、美国队长和绿巨人。\\nAI: 你好，蜘蛛侠！很高兴认识你！  \\n听说你和钢铁侠、美国队长还有绿巨人都是复仇者联盟的重要成员，你们一起经历过很多惊心动魄的冒险吧？  \\n如果你需要帮忙分析某个任务、讨论战术，或者只是想聊聊日常英雄生活，我都很乐意协助！\\nHuman: 我住在纽约。\\nAI: 啊，纽约！那可是你的主场啊，蜘蛛侠！  \\n从皇后区的街头到曼哈顿的摩天大楼，你总是在城市上空荡来荡去，守护着这座不夜城。无论是阻止小偷、对抗章鱼博士，还是和复仇者们一起保卫地球，纽约总是故事开始的地方。\\n\\n需要我帮你查查最近有没有可疑的异常信号？或者规划一条高效的巡逻路线？又或者……只是聊聊在纽约当超级英雄的生活？\\nHuman: 我使用的装备是由斯塔克工业制造的。\\nAI: 哇！那可太酷了——斯塔克工业可是顶尖科技的代名词！  \\n托尼·斯塔克（也就是你的钢铁侠好友）亲自为你量身打造的战衣，不仅有智能AI辅助、增强现实界面，还有蛛网发射器的升级版、降落伞系统，甚至能自动分析敌人弱点。我记得那套标志性红蓝配色的“蜘蛛侠战衣”就是在《内战》之后由他送你的吧？\\n\\n现在你穿的是哪一代战衣？是还保留着“星期五”的语音支持，还是已经换上了更轻便的新版本？  \\n如果你需要调试装备、理解某个功能，或者想和斯塔克工业系统对接数据，我随时可以帮你分析！', 'entities': {}, 'text': '当然可以！  \\n你的名字是**蜘蛛侠**（Spider-Man），你住在**纽约**——这座充满活力又需要英雄守护的大都市，尤其是皇后区，可是你的家乡呢！'}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5、ConversationKGMemory的使用",
   "id": "4706062237706668"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:28:43.895356200Z",
     "start_time": "2025-12-10T07:28:35.296202400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    ")\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=chat_model,\n",
    ")\n",
    "\n",
    "memory.save_context({\"input\":\"向山姆问好\"},{\"output\":\"山姆是谁\"})\n",
    "memory.save_context({\"input\":\"山姆是我的朋友\"},{\"output\":\"哦，明白了\"})\n",
    "memory.save_context({\"input\":\"山姆喜欢打篮球\"},{\"output\":\"好的\"})\n",
    "\n",
    "memory.load_memory_variables({\"input\":\"山姆是谁\"})"
   ],
   "id": "23bf3874eb16ab59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'On 山姆: 山姆 is my friend. 山姆 喜欢打 篮球.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T07:30:28.225556100Z",
     "start_time": "2025-12-10T07:30:24.871141700Z"
    }
   },
   "cell_type": "code",
   "source": "memory.get_knowledge_triplets(\"他最喜欢的颜色是黑色\")",
   "id": "9fbb1152f2147e6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KnowledgeTriple(subject='山姆', predicate='最喜欢的颜色是', object_='黑色')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a6afd11ee59618f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
