{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1、字符串输出解析器 StrOutParser",
   "id": "95525bf761606543"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-08T02:18:31.309829Z",
     "start_time": "2025-12-08T02:18:12.317623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "import dotenv\n",
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser, XMLOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "# 调用大模型\n",
    "response = chat_model.invoke(\"什么是大语言模型？\")\n",
    "print(\"=\"*20)\n",
    "print(type(response))\n",
    "\n",
    "# 如何获取一个字符串的输出结果呢？\n",
    "# 方式1：自己调用输出结果的content\n",
    "print(\"=\"*20)\n",
    "print(response.content)\n",
    "\n",
    "# 方式2：使用输出解析器\n",
    "str_out_parser = StrOutputParser()\n",
    "str_response = str_out_parser.parse(response)\n",
    "print(\"=\"*20)\n",
    "print(type(str_response))\n",
    "print(str_response)\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "====================\n",
      "大语言模型（Large Language Model，简称 LLM）是一种基于深度学习的人工智能模型，专门用于理解和生成人类语言。它通过在大量文本数据上进行训练，学习语言的统计规律、语法结构、语义关系以及世界知识，从而能够完成多种自然语言处理任务。\n",
      "\n",
      "### 核心特点：\n",
      "\n",
      "1. **规模庞大**：\n",
      "   - 大语言模型通常包含数十亿甚至数千亿个参数（如 GPT-3 有约 1750 亿参数），这使得它们具有强大的表达能力和泛化能力。\n",
      "   - 训练数据量巨大，涵盖书籍、网页、新闻、百科、代码等多种来源。\n",
      "\n",
      "2. **基于 Transformer 架构**：\n",
      "   - 当前主流的大语言模型（如 GPT、BERT、PaLM、LLaMA 等）大多采用 Transformer 神经网络结构，该结构擅长处理长距离依赖和并行计算。\n",
      "\n",
      "3. **自回归或双向建模**：\n",
      "   - 像 GPT 系列采用**自回归**方式（从左到右逐词预测下一个词），适合文本生成。\n",
      "   - 像 BERT 采用**双向编码**，更适合理解上下文（如问答、分类）。\n",
      "\n",
      "4. **通用性与零样本/少样本学习能力**：\n",
      "   - 大语言模型在训练后无需针对每个任务重新训练，就能通过提示（prompt）完成多种任务，例如翻译、摘要、问答、写代码等。\n",
      "   - 在没有或仅有少量示例的情况下（零样本或少样本学习），也能表现出色。\n",
      "\n",
      "5. **生成与理解能力兼备**：\n",
      "   - 不仅能“读懂”输入文本的含义，还能生成连贯、合理、有时甚至富有创意的文本。\n",
      "\n",
      "### 典型应用：\n",
      "\n",
      "- 智能客服与对话系统（如 ChatGPT）\n",
      "- 内容创作（写文章、诗歌、剧本）\n",
      "- 编程辅助（GitHub Copilot）\n",
      "- 机器翻译\n",
      "- 信息检索与摘要\n",
      "- 教育辅导与知识问答\n",
      "\n",
      "### 局限性：\n",
      "\n",
      "- 可能产生“幻觉”（即生成看似合理但事实错误的内容）\n",
      "- 对训练数据中的偏见敏感\n",
      "- 难以保证逻辑一致性或长期记忆\n",
      "- 计算资源消耗大，部署成本高\n",
      "\n",
      "总之，大语言模型是当前人工智能在自然语言处理领域的重要突破，正在深刻改变人机交互和信息处理的方式。\n",
      "====================\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='大语言模型（Large Language Model，简称 LLM）是一种基于深度学习的人工智能模型，专门用于理解和生成人类语言。它通过在大量文本数据上进行训练，学习语言的统计规律、语法结构、语义关系以及世界知识，从而能够完成多种自然语言处理任务。\\n\\n### 核心特点：\\n\\n1. **规模庞大**：\\n   - 大语言模型通常包含数十亿甚至数千亿个参数（如 GPT-3 有约 1750 亿参数），这使得它们具有强大的表达能力和泛化能力。\\n   - 训练数据量巨大，涵盖书籍、网页、新闻、百科、代码等多种来源。\\n\\n2. **基于 Transformer 架构**：\\n   - 当前主流的大语言模型（如 GPT、BERT、PaLM、LLaMA 等）大多采用 Transformer 神经网络结构，该结构擅长处理长距离依赖和并行计算。\\n\\n3. **自回归或双向建模**：\\n   - 像 GPT 系列采用**自回归**方式（从左到右逐词预测下一个词），适合文本生成。\\n   - 像 BERT 采用**双向编码**，更适合理解上下文（如问答、分类）。\\n\\n4. **通用性与零样本/少样本学习能力**：\\n   - 大语言模型在训练后无需针对每个任务重新训练，就能通过提示（prompt）完成多种任务，例如翻译、摘要、问答、写代码等。\\n   - 在没有或仅有少量示例的情况下（零样本或少样本学习），也能表现出色。\\n\\n5. **生成与理解能力兼备**：\\n   - 不仅能“读懂”输入文本的含义，还能生成连贯、合理、有时甚至富有创意的文本。\\n\\n### 典型应用：\\n\\n- 智能客服与对话系统（如 ChatGPT）\\n- 内容创作（写文章、诗歌、剧本）\\n- 编程辅助（GitHub Copilot）\\n- 机器翻译\\n- 信息检索与摘要\\n- 教育辅导与知识问答\\n\\n### 局限性：\\n\\n- 可能产生“幻觉”（即生成看似合理但事实错误的内容）\\n- 对训练数据中的偏见敏感\\n- 难以保证逻辑一致性或长期记忆\\n- 计算资源消耗大，部署成本高\\n\\n总之，大语言模型是当前人工智能在自然语言处理领域的重要突破，正在深刻改变人机交互和信息处理的方式。' additional_kwargs={} response_metadata={'model_name': 'qwen3-max', 'finish_reason': 'stop', 'request_id': '47fe1522-50df-4edd-a882-c8dd805afb04', 'token_usage': {'input_tokens': 13, 'output_tokens': 528, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 541}} id='run--079e31a2-da84-46e0-b72d-1dd7cf3306a0-0'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2、json输出解析器 JsonOutputParser\n",
    "\n",
    "方式1："
   ],
   "id": "8ae5e4002d7f43a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:18:33.741847Z",
     "start_time": "2025-12-08T02:18:31.609769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "import dotenv\n",
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个靠谱的{role}。\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = chat_prompt_template.invoke(input={\n",
    "    \"role\": \"人工智能专家\",\n",
    "    \"question\": \"人工智能用英文怎么说？问题用q表示，回答用a表示，返回一个JSON格式的数据\"\n",
    "})\n",
    "\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response)\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "response_1 = parser.invoke(response)\n",
    "print(response_1)\n"
   ],
   "id": "175da3163c3bc997",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\\n  \"q\": \"人工智能用英文怎么说？\",\\n  \"a\": \"Artificial Intelligence\"\\n}' additional_kwargs={} response_metadata={'model_name': 'qwen3-max', 'finish_reason': 'stop', 'request_id': '917e5842-4ae3-4b09-a3e6-8470b83984f5', 'token_usage': {'input_tokens': 41, 'output_tokens': 22, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 63}} id='run--ab6fe697-1f70-46e2-932b-31e6904e5f08-0'\n",
      "{'q': '人工智能用英文怎么说？', 'a': 'Artificial Intelligence'}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "方式2：\n",
    "\n",
    "举例1："
   ],
   "id": "d7e953e6daa77e0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:18:33.772670Z",
     "start_time": "2025-12-08T02:18:33.759108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parser = JsonOutputParser()\n",
    "\n",
    "print(parser.get_format_instructions())"
   ],
   "id": "e6c5b8510d272484",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return a JSON object.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2：",
   "id": "b508017270aff090"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:32:33.802775Z",
     "start_time": "2025-12-08T02:32:30.010351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "joke_query = \"讲一个笑话。\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的查询。\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model | parser\n",
    "output = chain.invoke(joke_query)\n",
    "print(output)"
   ],
   "id": "26c78814e56be0a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': '为什么数学老师离婚了？因为他发现另一半是负数！'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3、XML输出解析器 XmlOutputParser\n",
    "\n",
    "举例1："
   ],
   "id": "1e271c3780e683e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:38:52.977923Z",
     "start_time": "2025-12-08T02:38:45.906111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(\"请生成周杰伦的歌单，将歌名附在<song>标签中，歌手附在<artist>标签中，返回XML格式的数据。\")\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)\n"
   ],
   "id": "2b3fb99136db03fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<playlist>\n",
      "  <track>\n",
      "    <song>晴天</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "  <track>\n",
      "    <song>七里香</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "  <track>\n",
      "    <song>青花瓷</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "  <track>\n",
      "    <song>稻香</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "  <track>\n",
      "    <song>夜曲</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "  <track>\n",
      "    <song>告白气球</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "  <track>\n",
      "    <song>简单爱</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "  <track>\n",
      "    <song>双截棍</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "  <track>\n",
      "    <song>龙卷风</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "  <track>\n",
      "    <song>菊花台</song>\n",
      "    <artist>周杰伦</artist>\n",
      "  </track>\n",
      "</playlist>\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2：",
   "id": "e36c0db41d8b9ded"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:40:06.221714Z",
     "start_time": "2025-12-08T02:40:06.202687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "\n",
    "parser = XMLOutputParser()\n",
    "parser.get_format_instructions()"
   ],
   "id": "2b7d1edbf957a4bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:51:19.987283Z",
     "start_time": "2025-12-08T02:51:15.921880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "chat_model = ChatTongyi(\n",
    "    model=\"qwen3-max\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    ")\n",
    "\n",
    "actor_query = \"生成汤姆·汉克斯的简短电影记录，使用中文回答。\"\n",
    "\n",
    "parser = XMLOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的查询。\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model | parser\n",
    "\n",
    "output = chain.invoke(actor_query)\n",
    "\n",
    "print(output)"
   ],
   "id": "5237dbb4b6e150fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': [{'actor': '汤姆·汉克斯'}, {'filmography': [{'movie': '《阿甘正传》'}, {'movie': '《拯救大兵瑞恩》'}, {'movie': '《费城故事》'}, {'movie': '《荒岛余生》'}, {'movie': '《菲利普斯船长》'}]}]}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "acf3a933f225fae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
